{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9511861d",
   "metadata": {},
   "source": [
    "### Project Overview\n",
    "\n",
    "In this project, a complete motor imagery EEG classification pipeline is implemented using the BCI Competition IV-2a dataset.  \n",
    "EEG signals are loaded from GDF files, while the corresponding trial labels are obtained from separate MAT files and aligned using trial onset markers.\n",
    "\n",
    "The EEG data are epoched into fixed time windows corresponding to motor imagery tasks and bandpass filtered to retain task-relevant frequency components.  \n",
    "Spatial features are extracted using the Common Spatial Patterns (CSP) algorithm. Since CSP is inherently binary, a one-vs-rest strategy is employed to extend it to four-class motor imagery classification.\n",
    "\n",
    "For each motor imagery class, a dedicated CSP model is trained against all remaining classes. The resulting log-variance features from all CSP models are concatenated to form a discriminative feature vector.  \n",
    "A Linear Discriminant Analysis (LDA) classifier is then trained on the training sessions and evaluated on the independent test sessions.\n",
    "\n",
    "The final performance is reported using subject-wise classification accuracy, as well as the mean and standard deviation of accuracy across all subjects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b70f72",
   "metadata": {},
   "source": [
    "### Data Loading (GDF + MAT labels)\n",
    "\n",
    "We load EEG signals from GDF files and read class labels from MAT files.\n",
    "Epochs are extracted using trial-start markers, then labels are aligned with epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a9f21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Channel names are not unique*\", category=RuntimeWarning)\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import scipy.io as sio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5318bf",
   "metadata": {},
   "source": [
    "### Helper: Load epochs from GDF and labels from MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d50922fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_epochs_and_labels(gdf_path, mat_path,\n",
    "                          tmin=2.0, tmax=6.0,\n",
    "                          l_freq=8.0, h_freq=30.0):\n",
    "    raw = mne.io.read_raw_gdf(gdf_path, preload=True, verbose=False)\n",
    "\n",
    "    raw.rename_channels({ch: f\"{ch}_{i:02d}\" for i, ch in enumerate(raw.ch_names)})\n",
    "\n",
    "    events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "    raw.pick(\"eeg\")\n",
    "\n",
    "    # --- labels from MAT ---\n",
    "    mat = sio.loadmat(mat_path)\n",
    "    y = mat[\"classlabel\"].squeeze().astype(int)   # classes: 1..4\n",
    "\n",
    "    # --- epoch on trial start (768) ---\n",
    "    epochs = mne.Epochs(\n",
    "        raw, events,\n",
    "        event_id={\"trial\": event_id[\"768\"]},\n",
    "        tmin=tmin, tmax=tmax,\n",
    "        baseline=None, preload=True,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # --- bandpass filter ---\n",
    "    epochs = epochs.filter(l_freq, h_freq, verbose=False)\n",
    "    X = epochs.get_data()  # (trials, ch, samples)\n",
    "\n",
    "    # align lengths just in case\n",
    "    n = min(len(X), len(y))\n",
    "    return X[:n], y[:n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831adcc6",
   "metadata": {},
   "source": [
    "### Single-subject demo (Train: A01T, Test: A01E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4216086e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((288, 25, 1001),\n",
       " (array([1, 2, 3, 4]), array([72, 72, 72, 72])),\n",
       " (288, 25, 1001),\n",
       " (array([1, 2, 3, 4]), array([72, 72, 72, 72])))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = \"./dataset/BCICIV_2a\"\n",
    "\n",
    "XT, yT = load_epochs_and_labels(f\"{base}/A01T.gdf\", f\"{base}/A01T.mat\")\n",
    "XE, yE = load_epochs_and_labels(f\"{base}/A01E.gdf\", f\"{base}/A01E.mat\")\n",
    "\n",
    "XT.shape, np.unique(yT, return_counts=True), XE.shape, np.unique(yE, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b0569f",
   "metadata": {},
   "source": [
    "### Binary Class Selection (Left vs Right) + CSP input formatting\n",
    "\n",
    "In MAT labels: 1=left, 2=right, 3=foot, 4=tongue\n",
    "We keep only {1,2} and relabel to {0,1}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c34a44c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25, 1001, 72), (25, 1001, 72), (144, 25, 1001), (144, 25, 1001))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep left(1) vs right(2)\n",
    "idxT = np.where((yT == 1) | (yT == 2))[0]\n",
    "idxE = np.where((yE == 1) | (yE == 2))[0]\n",
    "\n",
    "XT_lr, yT_lr = XT[idxT], yT[idxT]\n",
    "XE_lr, yE_lr = XE[idxE], yE[idxE]\n",
    "\n",
    "# relabel: left=0, right=1\n",
    "yT_lr = np.where(yT_lr == 1, 0, 1)\n",
    "yE_lr = np.where(yE_lr == 1, 0, 1)\n",
    "\n",
    "# CSP format: (ch, samples, trials) per class (TRAIN فقط)\n",
    "XA = XT_lr[yT_lr == 0].transpose(1, 2, 0)\n",
    "XB = XT_lr[yT_lr == 1].transpose(1, 2, 0)\n",
    "\n",
    "XA.shape, XB.shape, XT_lr.shape, XE_lr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6319f6f5",
   "metadata": {},
   "source": [
    "### CSP Training (on Train) + Feature Extraction (Train/Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61f814ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from filters.csp import CSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f87f126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((144, 4), (144, 4))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 2\n",
    "csp = CSP(m=m, reg=0.0)\n",
    "csp.fit(XA, XB)\n",
    "\n",
    "# features need: (ch, samples, trials)\n",
    "FT = csp.compute_features(XT_lr.transpose(1, 2, 0))  # (trials_train, 2m)\n",
    "FE = csp.compute_features(XE_lr.transpose(1, 2, 0))  # (trials_test,  2m)\n",
    "\n",
    "FT.shape, FE.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59536c67",
   "metadata": {},
   "source": [
    "### Train on T, Evaluate on E (LDA)\n",
    "\n",
    "Here we split the extracted CSP features into training and test sets (stratified), then train an LDA classifier and report the classification accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49ad13e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8263888888888888,\n",
       " array([[71,  1],\n",
       "        [24, 48]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(FT, yT_lr)\n",
    "\n",
    "y_pred = clf.predict(FE)\n",
    "\n",
    "acc = accuracy_score(yE_lr, y_pred)\n",
    "cm = confusion_matrix(yE_lr, y_pred)\n",
    "\n",
    "acc, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39444b9e",
   "metadata": {},
   "source": [
    " ### Subject-wise Evaluation (Train: T, Test: E)\n",
    "For each subject A01..A09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "335afa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A01 T->E accuracy: 0.826\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A02 T->E accuracy: 0.653\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A03 T->E accuracy: 0.917\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A04 T->E accuracy: 0.660\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A05 T->E accuracy: 0.625\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A06 T->E accuracy: 0.736\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A07 T->E accuracy: 0.646\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A08 T->E accuracy: 0.958\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A09 T->E accuracy: 0.750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7523148148148148, 0.11606436237705253)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects = [f\"A0{i}\" for i in range(1, 10)]\n",
    "accs = []\n",
    "\n",
    "for subj in subjects:\n",
    "    XT, yT = load_epochs_and_labels(f\"{base}/{subj}T.gdf\", f\"{base}/{subj}T.mat\")\n",
    "    XE, yE = load_epochs_and_labels(f\"{base}/{subj}E.gdf\", f\"{base}/{subj}E.mat\")\n",
    "\n",
    "    # left vs right only\n",
    "    idxT = np.where((yT == 1) | (yT == 2))[0]\n",
    "    idxE = np.where((yE == 1) | (yE == 2))[0]\n",
    "\n",
    "    XT_lr, yT_lr = XT[idxT], yT[idxT]\n",
    "    XE_lr, yE_lr = XE[idxE], yE[idxE]\n",
    "\n",
    "    yT_lr = np.where(yT_lr == 1, 0, 1)\n",
    "    yE_lr = np.where(yE_lr == 1, 0, 1)\n",
    "\n",
    "    XA = XT_lr[yT_lr == 0].transpose(1, 2, 0)\n",
    "    XB = XT_lr[yT_lr == 1].transpose(1, 2, 0)\n",
    "\n",
    "    csp = CSP(m=2, reg=0.0)\n",
    "    csp.fit(XA, XB)\n",
    "\n",
    "    FT = csp.compute_features(XT_lr.transpose(1, 2, 0))\n",
    "    FE = csp.compute_features(XE_lr.transpose(1, 2, 0))\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(FT, yT_lr)\n",
    "\n",
    "    y_pred = clf.predict(FE)\n",
    "    acc = accuracy_score(yE_lr, y_pred)\n",
    "    accs.append(acc)\n",
    "\n",
    "    print(f\"{subj} T->E accuracy: {acc:.3f}\")\n",
    "\n",
    "mean_acc = float(np.mean(accs))\n",
    "std_acc  = float(np.std(accs))\n",
    "\n",
    "mean_acc, std_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a91e501",
   "metadata": {},
   "source": [
    "### 4-class CSP (One-vs-Rest)\n",
    "\n",
    "For four-class motor imagery, we train one CSP model per class using a one-vs-rest strategy (class k vs all other classes).  \n",
    "For each CSP model we extract log-variance features (first `m` + last `m` components), then concatenate features from all four models and train a multi-class classifier (LDA).  \n",
    "Training is done on `A??T` and evaluation is performed on `A??E`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c795d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# labels in MAT: 1=left, 2=right, 3=foot, 4=tongue\n",
    "CLASSES = [1, 2, 3, 4]\n",
    "\n",
    "def ovr_csp_features(X, y, m=2, reg=0.0):\n",
    "    from filters.csp import CSP\n",
    "\n",
    "    csps = []\n",
    "    feats = []\n",
    "\n",
    "    for k in CLASSES:\n",
    "        # class k vs rest\n",
    "        idx_pos = np.where(y == k)[0]\n",
    "        idx_neg = np.where(y != k)[0]\n",
    "\n",
    "        X_pos = X[idx_pos]\n",
    "        X_neg = X[idx_neg]\n",
    "\n",
    "        XA = X_pos.transpose(1, 2, 0)  # (ch, samp, trials)\n",
    "        XB = X_neg.transpose(1, 2, 0)\n",
    "\n",
    "        csp = CSP(m=m, reg=reg)\n",
    "        csp.fit(XA, XB)\n",
    "        csps.append(csp)\n",
    "\n",
    "        Fk = csp.compute_features(X.transpose(1, 2, 0))  # (trials, 2m)\n",
    "        feats.append(Fk)\n",
    "\n",
    "    F = np.concatenate(feats, axis=1)  # (trials, 4*2m)\n",
    "    return csps, F\n",
    "\n",
    "def ovr_csp_transform(csps, X):\n",
    "    feats = []\n",
    "    Xt = X.transpose(1, 2, 0)  # (ch, samp, trials)\n",
    "    for csp in csps:\n",
    "        feats.append(csp.compute_features(Xt))  # (trials, 2m)\n",
    "    return np.concatenate(feats, axis=1)       # (trials, 4*2m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "39c127eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7361111111111112,\n",
       " array([[62,  3,  2,  5],\n",
       "        [19, 46,  4,  3],\n",
       "        [ 1,  1, 49, 21],\n",
       "        [ 1,  0, 16, 55]]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Single-subject 4-class: Train on T, Test on E ---\n",
    "base = \"./dataset/BCICIV_2a\"\n",
    "\n",
    "XT, yT = load_epochs_and_labels(f\"{base}/A01T.gdf\", f\"{base}/A01T.mat\")\n",
    "XE, yE = load_epochs_and_labels(f\"{base}/A01E.gdf\", f\"{base}/A01E.mat\")\n",
    "\n",
    "m = 2\n",
    "csps, FT = ovr_csp_features(XT, yT, m=m, reg=0.0)\n",
    "FE = ovr_csp_transform(csps, XE)\n",
    "\n",
    "clf = LinearDiscriminantAnalysis()\n",
    "clf.fit(FT, yT)\n",
    "y_pred = clf.predict(FE)\n",
    "\n",
    "acc = accuracy_score(yE, y_pred)\n",
    "cm = confusion_matrix(yE, y_pred, labels=CLASSES)\n",
    "\n",
    "acc, cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9545a0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A01 4-class T->E accuracy: 0.736\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A02 4-class T->E accuracy: 0.517\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A03 4-class T->E accuracy: 0.753\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A04 4-class T->E accuracy: 0.628\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A05 4-class T->E accuracy: 0.469\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A06 4-class T->E accuracy: 0.458\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A07 4-class T->E accuracy: 0.674\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A08 4-class T->E accuracy: 0.764\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('769'), np.str_('770'), np.str_('771'), np.str_('772')]\n",
      "Used Annotations descriptions: [np.str_('1023'), np.str_('1072'), np.str_('276'), np.str_('277'), np.str_('32766'), np.str_('768'), np.str_('783')]\n",
      "A09 4-class T->E accuracy: 0.667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6296296296296297, 0.11344954402632265)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects = [f\"A0{i}\" for i in range(1, 10)]\n",
    "accs = []\n",
    "\n",
    "for subj in subjects:\n",
    "    XT, yT = load_epochs_and_labels(f\"{base}/{subj}T.gdf\", f\"{base}/{subj}T.mat\")\n",
    "    XE, yE = load_epochs_and_labels(f\"{base}/{subj}E.gdf\", f\"{base}/{subj}E.mat\")\n",
    "\n",
    "    csps, FT = ovr_csp_features(XT, yT, m=2, reg=0.0)\n",
    "    FE = ovr_csp_transform(csps, XE)\n",
    "\n",
    "    clf = LinearDiscriminantAnalysis()\n",
    "    clf.fit(FT, yT)\n",
    "\n",
    "    y_pred = clf.predict(FE)\n",
    "    acc = accuracy_score(yE, y_pred)\n",
    "    accs.append(acc)\n",
    "\n",
    "    print(f\"{subj} 4-class T->E accuracy: {acc:.3f}\")\n",
    "\n",
    "mean_acc = float(np.mean(accs))\n",
    "std_acc  = float(np.std(accs))\n",
    "\n",
    "mean_acc, std_acc\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
